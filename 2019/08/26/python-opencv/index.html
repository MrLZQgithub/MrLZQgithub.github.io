<!DOCTYPE HTML>
<html>

<head><meta name="generator" content="Hexo 3.8.0">
	<link rel="bookmark" type="image/x-icon" href="/img/lolo.png">
	<link rel="shortcut icon" href="/img/lolo.png">
	
			    <title>
    Mr.LZQ
    </title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <link rel="stylesheet" href="/css/mic_main.css">
    <link rel="stylesheet" href="/css/dropdownMenu.css">
    <meta name="keywords" content="lzqpoewrs">
    
    	<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
	 
    <noscript>
        <link rel="stylesheet" href="/css/noscript.css">
    </noscript>
    <style type="text/css">
        body:before {
          content: ' ';
          position: fixed;
          top: 0;
          background: url('/img/bg.jpg') center 0 no-repeat;
          right: 0;
          bottom: 0;
          left: 0;
          background-size: cover; 
        }
    </style>

			    
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script async type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


    <script src="/js/jquery.min.js"></script>
    <script src="/js/jquery.scrollex.min.js"></script>
    <script src="/js/jquery.scrolly.min.js"></script>
    <script src="/js/skel.min.js"></script>
    <script src="/js/util.js"></script>
    <script src="/js/main.js"></script>
	
</head>
    
		
<!-- Layouts -->



<!--  代码渲染  -->
<link rel="stylesheet" href="/css/prism_coy.css">
<link rel="stylesheet" href="/css/typo.css">
<!-- 文章页 -->
<body class="is-loading">
    <!-- Wrapper 外包 s-->
    <div id="wrapper" class="fade-in">
        <!-- Intro 头部显示 s -->
        <!-- Intro 头部显示 e -->
        <!-- Header 头部logo start -->
        <header id="header">
    <a href="/" class="logo">LZQ</a>
</header>
        <!-- Nav 导航条 start -->
        <nav id="nav" class="special">
            <ul class="menu links">
			<!-- Homepage  主页  --> 
			<li>
	            <a href="/" rel="nofollow">主页</a>
	        </li>
			<!-- categories_name  分类   --> 
	        
	        <li class="active">
	            <a href="#s1">分类</a>
	                    <ul class="submenu">
	                        <li>
	                        <a class="category-link" href="/categories/c/">c++</a></li><li><a class="category-link" href="/categories/python/">python</a></li><li><a class="category-link" href="/categories/pyton/">pyton</a></li><li><a class="category-link" href="/categories/实用/">实用</a></li><li><a class="category-link" href="/categories/嵌入式/">嵌入式</a>
	                    </li></ul>
	        </li>
	        
	        <!-- archives  归档   --> 
	        
	        
		        <!-- Pages 自定义   -->
		        
		        <li>
		            <a href="/about/" title="简历">
		                简历
		            </a>
		        </li>
		        
		        <li>
		            <a href="/group/" title="团队">
		                团队
		            </a>
		        </li>
		        
		        <li>
		            <a href="/gallery/" title="图库">
		                图库
		            </a>
		        </li>
		        
		        <li>
		            <a href="/tag/" title="标签">
		                标签
		            </a>
		        </li>
		        


            </ul>
            <!-- icons 图标   -->
			<ul class="icons">
                    
                    <li>
                        <a title="github" href="https://github.com/lzqmove" target="_blank" rel="noopener">
                            <i class="icon fa fa-github"></i>
                        </a>
                    </li>
                    
                    <li>
                        <a title="500px" href="http://500px.com" target="_blank" rel="noopener">
                            <i class="icon fa fa-500px"></i>
                        </a>
                    </li>
                    
			</ul>
</nav>

        <div id="main">
            <div class="post_page_title_img" style="height: 25rem;background-image: url(https://upload-images.jianshu.io/upload_images/16271012-d7e69820d7306670.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240);background-position: center; background-repeat:no-repeat; background-size:cover;-moz-background-size:cover;overflow:hidden;">
                <a href="#" style="padding: 4rem 4rem 2rem 4rem ;"><h2>Python-opencv</h2></a>
            </div>
            <!-- Post -->
            <div class="typo" style="padding: 3rem;">
                <h1 id="一、Python-opencv-应用"><a href="#一、Python-opencv-应用" class="headerlink" title="一、Python-opencv 应用"></a>一、Python-opencv 应用</h1><h2 id="首先，安装好python，anaconda、pycharm"><a href="#首先，安装好python，anaconda、pycharm" class="headerlink" title="首先，安装好python，anaconda、pycharm"></a>首先，安装好python，anaconda、pycharm</h2><h2 id="测试程序-调用摄像头"><a href="#测试程序-调用摄像头" class="headerlink" title="测试程序-调用摄像头"></a>测试程序-调用摄像头</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import cv2 #导入opencv库</span><br><span class="line">cap = cv2.VideoCapture(0) #调用摄像头，参数是设备编号</span><br><span class="line">#主循环是读取摄像头图像，按q停止</span><br><span class="line">while True:</span><br><span class="line">    ret, frame = cap.read()</span><br><span class="line">    cv2.imshow(&apos;video&apos;,frame)</span><br><span class="line">    if cv2.waitKey(1) &amp; 0xFF == ord(&apos;q&apos;):</span><br><span class="line">        break</span><br><span class="line">cap.release() #释放cap </span><br><span class="line">cv2.destroyAllWindows()#销毁所有窗口</span><br></pre></td></tr></table></figure>
<h1 id="二、颜色空间转换"><a href="#二、颜色空间转换" class="headerlink" title="二、颜色空间转换"></a>二、颜色空间转换</h1><p>OpenCV 中有数百种不同色彩空间转换的方法。当前最主要的,最常用的有三种颜色空间:灰度,BGR,HSV。<br>⚫ 灰度色彩空间是通过去除彩色信息来将其转换为灰阶,灰度色彩空间对中间处理特别有效,比如人脸检测。<br>⚫ BGR,即蓝-绿-红色彩空间,每一个像素点由一个三元数来表示,分别代表蓝绿红三种颜色<br>⚫ HSV,H(Hue)是色调,用角度度量,取值范围为 0°~360°,从红色开始按逆时针方向计算,红色为 0°,绿色为 120°,蓝色为 240°,S(Saturation)是饱和度,V(Value)表示黑暗程度。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import cv2</span><br><span class="line">cap = cv2.VideoCapture(0)</span><br><span class="line">while True:</span><br><span class="line">    ret, frame = cap.read()</span><br><span class="line">    cv2.imshow(&apos;video&apos;,frame)</span><br><span class="line">    #灰度转化</span><br><span class="line">    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)</span><br><span class="line">    cv2.imshow(&apos;gray&apos;,gray)</span><br><span class="line">    #hsv转化</span><br><span class="line">    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)</span><br><span class="line">    cv2.imshow(&apos;hsv&apos;, hsv)</span><br><span class="line">    if cv2.waitKey(1) &amp; 0xFF == ord(&apos;q&apos;):</span><br><span class="line">        break</span><br><span class="line">cap.release()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure></p>
<h1 id="三、图像缩放"><a href="#三、图像缩放" class="headerlink" title="三、图像缩放"></a>三、图像缩放</h1><p>很多时候,读取图像过于清晰,会导致像素点过多,读取缓慢,影响效率,下面介绍 Opencv是如何在保留最大信息的前提下缩放图像的。<br> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">cap = cv2.VideoCapture(0)</span><br><span class="line">while True:</span><br><span class="line">    ret, frame = cap.read()</span><br><span class="line">    cv2.imshow(&apos;video&apos;,frame)</span><br><span class="line">    #第 8 行, shape ()函数返回一个列表,这个列表第一个元素是图像宽度,第二个元素是图像高度,分别赋值为 x,y</span><br><span class="line">    x, y = frame.shape[0:2]</span><br><span class="line">    #第 9 行，resize 函数,将图像缩小为原图 1/4 大小，x/2,y/2</span><br><span class="line">    small_frame = cv2.resize(frame, (int(y/2), int(x/2)))</span><br><span class="line">    cv2.imshow(&apos;small&apos;, small_frame)</span><br><span class="line">    if cv2.waitKey(1) &amp; 0xFF == ord(&apos;q&apos;):</span><br><span class="line">        break</span><br><span class="line">cap.release()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure></p>
<h1 id="四、图像滤波"><a href="#四、图像滤波" class="headerlink" title="四、图像滤波"></a>四、图像滤波</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">cap = cv2.VideoCapture(0)</span><br><span class="line">while True:</span><br><span class="line">    ret, frame = cap.read()</span><br><span class="line">    #cv2.imshow(&apos;video&apos;,frame)</span><br><span class="line">    x, y = frame.shape[0:2]</span><br><span class="line">    small_frame = cv2.resize(frame, (int(y/2), int(x/2)))</span><br><span class="line">    cv2.imshow(&apos;small&apos;, small_frame)</span><br><span class="line">    #Blur:模糊滤波</span><br><span class="line">    img_mean = cv2.blur(small_frame, (5,5))</span><br><span class="line">    #Gaussianblur:高斯滤波</span><br><span class="line">    img_Guassian = cv2.GaussianBlur(small_frame, (5,5), 0)</span><br><span class="line">    #Median:中值滤波</span><br><span class="line">    img_median = cv2.medianBlur(small_frame, 5)</span><br><span class="line">    #Bilater:双边滤波</span><br><span class="line">    img_bilater = cv2.bilateralFilter(small_frame, 9, 75, 75)</span><br><span class="line">    cv2.imshow(&apos;mean&apos;, img_mean)</span><br><span class="line">    cv2.imshow(&apos;guassian&apos;, img_Guassian)</span><br><span class="line">    cv2.imshow(&apos;median&apos;, img_median)</span><br><span class="line">    cv2.imshow(&apos;bilater&apos;, img_bilater)</span><br><span class="line">    if cv2.waitKey(1) &amp; 0xFF == ord(&apos;q&apos;):</span><br><span class="line">        break</span><br><span class="line">cap.release()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<h1 id="五、颜色识别or轮廓提取"><a href="#五、颜色识别or轮廓提取" class="headerlink" title="五、颜色识别or轮廓提取"></a>五、颜色识别or轮廓提取</h1><p>在 opencv 中颜色识别是最基础,应用最多的内容,一般来讲,在 opencv 中识别特定的颜色需要以下几个步骤:</p>
<p>颜色空间转换,将 BGR 转化为 HSV 颜色空间,利用色调区别颜色<br>按照阈值滤出所识别的颜色<br>连续的开闭运算,消除噪点,平滑边界<br>提取连通域,提取出要识别的颜色<br>开闭运算就是连续的腐蚀膨胀。<br>开运算:先腐蚀再膨胀,用来消除小物体<br>闭运算:先膨胀再腐蚀,用于排除小型黑洞<br>例程：识别红色和黄色组成的火焰,提取火轮廓。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">cap=cv2.VideoCapture(0)#创建视频窗口</span><br><span class="line">red_min=np.array([0,128,46])#设置红色最小值</span><br><span class="line">red_max=np.array([5,255,255])#设置红色最大值</span><br><span class="line">red2_min=np.array([156,128,46])#设置红色2最小值</span><br><span class="line">red2_max=np.array([180,255,255])#设置红色2最大值</span><br><span class="line">yellow_min=np.array([15,128,46])#设置黄色最小值</span><br><span class="line">yellow_max=np.array([50,255,255])#设置黄色最大值</span><br><span class="line">while True:</span><br><span class="line">    ret,frame=cap.read()#读取摄像头</span><br><span class="line">    cv2.imshow(&apos;video&apos;,frame)#显示摄像头</span><br><span class="line">    x,y=frame.shape[0:2]</span><br><span class="line">    small_frame=cv2.resize(frame,(int(y/2),int(x/2)))</span><br><span class="line">    cv2.imshow(&apos;small&apos;,small_frame)</span><br><span class="line">    src=small_frame.copy()</span><br><span class="line">    res=src.copy()</span><br><span class="line">    hsv=cv2.cvtColor(src,cv2.COLOR_BGR2HSV)#转化为hsv</span><br><span class="line">    cv2.imshow(&apos;hsv&apos;,hsv)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    #二值化，只提取出满足阈值的像素点</span><br><span class="line">    mask_red1=cv2.inRange(hsv,red_min,red_max)</span><br><span class="line">    mask_red2=cv2.inRange(hsv,red2_min,red2_max)</span><br><span class="line">    mask_yellow=cv2.inRange(hsv,yellow_min,yellow_max)</span><br><span class="line">    mask=cv2.bitwise_or(mask_red1,mask_red2)</span><br><span class="line">    mask=cv2.bitwise_or(mask,mask_yellow)</span><br><span class="line">    res=cv2.bitwise_and(src,src,mask=mask)</span><br><span class="line">    h,w=res.shape[:2]</span><br><span class="line">    blured=cv2.blur(res,(5,5))</span><br><span class="line">    ret,bright=cv2.threshold(blured,10,255,cv2.THRESH_BINARY)</span><br><span class="line">    gray=cv2.cvtColor(bright,cv2.COLOR_BGR2GRAY)</span><br><span class="line">    #连续开闭运算</span><br><span class="line">    kernel=cv2.getStructuringElement(cv2.MORPH_RECT,(5,5))</span><br><span class="line">    opened=cv2.morphologyEx(gray,cv2.MORPH_OPEN,kernel)</span><br><span class="line">    closed=cv2.morphologyEx(opened,cv2.MORPH_CLOSE,kernel)</span><br><span class="line">    #提取连通域,得到全部红色黄色区间</span><br><span class="line">    contours,hierarchy=cv2.findContours(closed,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)</span><br><span class="line">    cv2.drawContours(src,contours,-1,(255,0,0),2)</span><br><span class="line">    #提取火焰轮廓</span><br><span class="line">    cv2.imshow(&apos;result&apos;,src)</span><br><span class="line">    if cv2.waitKey(1) &amp; 0xFF == ord(&apos;q&apos;):</span><br><span class="line">        break</span><br><span class="line">cap.release()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure></p>
<h1 id="六、形状检测"><a href="#六、形状检测" class="headerlink" title="六、形状检测"></a>六、形状检测</h1><h2 id="直线检测"><a href="#直线检测" class="headerlink" title="直线检测"></a>直线检测</h2><p>直线检测可以通过 HoughLines 和 HoughLinesP 函数来完成,它们仅有的差别是:<br>第一个函数使用标准 Hough 变换,第二个函数使用概率 Hough 变换。HoughlinesP函数之所以称为概率版本的 Hough 变换是因为它只通过分析点的子集并估计这些点都属于一条直线的概率,这是标准 Hough 变换的优化版本。该函数计算代价少,执行更快。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">cap = cv2.VideoCapture(0)</span><br><span class="line">while True:</span><br><span class="line">    ret, frame = cap.read()</span><br><span class="line">    x, y = frame.shape[0:2]</span><br><span class="line">    small_frame = cv2.resize(frame, (int(y/2), int(x/2)))</span><br><span class="line">    cv2.imshow(&apos;small&apos;, small_frame)</span><br><span class="line">    gray = cv2.cvtColor(small_frame, cv2.COLOR_BGR2GRAY)</span><br><span class="line">    edges = cv2.Canny(gray, 50, 120)</span><br><span class="line">    minLineLength = 10</span><br><span class="line">    maxLineGap = 5</span><br><span class="line">    lines = cv2.HoughLinesP(edges, 1, np.pi/180, 100, minLineLength, maxLineGap)</span><br><span class="line">    for x1, y1, x2, y2 in lines[0]:</span><br><span class="line">        cv2.line(small_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)</span><br><span class="line">    cv2.imshow(&quot;lines&quot;, small_frame)</span><br><span class="line">    if cv2.waitKey(1) &amp; 0xFF == ord(&apos;q&apos;):</span><br><span class="line">        break</span><br><span class="line">cap.release()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure></p>
<h2 id="圆形检测"><a href="#圆形检测" class="headerlink" title="圆形检测"></a>圆形检测</h2><p>OpenCV 的 HoughCircles 函数可以用来检测圆,它与使用 HoughLines 函数类似。像用来决定删除或保留直线的两个参数 minLineLength 和 maxLineGap 一样,HoughCIrcles 有一个圆心间最小距离和圆的最小及最大半径。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">cap = cv2.VideoCapture(0)</span><br><span class="line">while True:</span><br><span class="line">    ret, frame = cap.read()</span><br><span class="line">    x, y = frame.shape[0:2]</span><br><span class="line">    small_frame = cv2.resize(frame, (int(y/2), int(x/2)))</span><br><span class="line">    cv2.imshow(&apos;small&apos;, small_frame)</span><br><span class="line">    gray = cv2.cvtColor(small_frame, cv2.COLOR_BGR2GRAY)</span><br><span class="line">    gray_img = cv2.medianBlur(gray, 5)</span><br><span class="line">    cimg = cv2.cvtColor(gray_img, cv2.COLOR_GRAY2BGR)</span><br><span class="line">    circles = cv2.HoughCircles(gray_img, cv2.HOUGH_GRADIENT, 1, 120, param1=100,</span><br><span class="line">    param2=30, minRadius=0, maxRadius=0)</span><br><span class="line">    circles = np.uint16(np.around(circles))</span><br><span class="line">    for i in circles[0,:]:</span><br><span class="line">        cv2.circle(small_frame, (i[0], i[1]), i[2], (0, 255, 0), 2)</span><br><span class="line">        cv2.circle(small_frame, (i[0], i[1]), 2, (0, 0, 255), 3)</span><br><span class="line">    cv2.imshow(&quot;circles&quot;, small_frame)</span><br><span class="line">    if cv2.waitKey(1) &amp; 0xFF == ord(&apos;q&apos;):</span><br><span class="line">        break</span><br><span class="line">cap.release()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure></p>
<h2 id="检测其他形状"><a href="#检测其他形状" class="headerlink" title="检测其他形状"></a>检测其他形状</h2><p> Opencv 中提供了 approxPloyDP 函数来检测所有形状,该函数提供多边形<br> 近似,如果您要检测的图形有多边形,结合 cv2.findContours 函数和<br>  cv2.approxPloyDP 函数,可以相当准确的检测出来。</p>
<h1 id="七、人脸识别"><a href="#七、人脸识别" class="headerlink" title="七、人脸识别"></a>七、人脸识别</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">import sys</span><br><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">def read_images(path, sz=None):</span><br><span class="line">    c = 0</span><br><span class="line">    X, y = [], []</span><br><span class="line">    names = []</span><br><span class="line">    for dirname, dirnames, filenames in os.walk(path):</span><br><span class="line">        for subdirname in dirnames:</span><br><span class="line">            subject_path = os.path.join(dirname, subdirname)</span><br><span class="line">            for filename in os.listdir(subject_path):</span><br><span class="line">                try:</span><br><span class="line">                    if (filename == &quot;.directory&quot;):</span><br><span class="line">                        continue</span><br><span class="line">                    filepath = os.path.join(subject_path, filename)</span><br><span class="line">                    im = cv2.imread(os.path.join(subject_path, filename), cv2.IMREAD_GRAYSCALE)</span><br><span class="line">                    if (im is None):</span><br><span class="line">                        print(&quot;image&quot; + filepath + &quot;is None&quot;)</span><br><span class="line">                    if (sz is not None):</span><br><span class="line">                        im = cv2.resize(im, sz)</span><br><span class="line">                    X.append(np.asarray(im, dtype=np.uint8))</span><br><span class="line">                    y.append(c)</span><br><span class="line">                except:</span><br><span class="line">                    print(&quot;unexpected error&quot;)</span><br><span class="line">                    raise</span><br><span class="line">            c = c+1</span><br><span class="line">            names.append(subdirname)</span><br><span class="line">    return [names, X, y]</span><br><span class="line">def face_rec():</span><br><span class="line">    read_dir = &quot;/home/cdq/pythonStudy/auto/model/data&quot;</span><br><span class="line">    [names, X, y] = read_images(read_dir)</span><br><span class="line">    y = np.asarray(y, dtype=np.int32)</span><br><span class="line">    model = cv2.face_EigenFaceRecognizer.create()</span><br><span class="line">    model.train(np.asarray(X), np.asarray(y))</span><br><span class="line">    face_cascade=cv2.CascadeClassifier(&apos;/home/cdq/pythonStudy/auto/model/haarcascade_frontalface_default.xml&apos;)</span><br><span class="line">    cap = cv2.VideoCapture(0)</span><br><span class="line">    while True:</span><br><span class="line">        ret, frame = cap.read()</span><br><span class="line">        x, y = frame.shape[0:2]</span><br><span class="line">        small_frame = cv2.resize(frame, (int(y/2), int(x/2)))</span><br><span class="line">        result = small_frame.copy()</span><br><span class="line">        gray = cv2.cvtColor(small_frame, cv2.COLOR_BGR2GRAY)</span><br><span class="line">        faces = face_cascade.detectMultiScale(gray, 1.3, 5)</span><br><span class="line">        for (x, y, w, h) in faces:</span><br><span class="line">            result = cv2.rectangle(result, (x, y), (x+w, y+h), (255, 0, 0), 2)</span><br><span class="line">            roi = gray[x:x+w, y:y+h]</span><br><span class="line">            try:</span><br><span class="line">                roi = cv2.resize(roi, (200,200), interpolation=cv2.INTER_LINEAR)</span><br><span class="line">                [p_label, p_confidence] = model.predict(roi)</span><br><span class="line">                #print(names[p_label])</span><br><span class="line">                cv2.putText(result, names[p_label], (x, y-20), cv2.FONT_HERSHEY_SIMPLEX,1, 255, 2)</span><br><span class="line">            except:</span><br><span class="line">                continue</span><br><span class="line">        cv2.imshow(&quot;recognize_face&quot;, result)</span><br><span class="line">        if cv2.waitKey(30) &amp; 0xFF == ord(&apos;q&apos;):</span><br><span class="line">            break</span><br><span class="line">    cap.release()</span><br><span class="line">    cv2.destroyAllWindows()</span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    face_rec()</span><br></pre></td></tr></table></figure>
<h1 id="八、二维码识别"><a href="#八、二维码识别" class="headerlink" title="八、二维码识别"></a>八、二维码识别</h1><h2 id="二维码定位"><a href="#二维码定位" class="headerlink" title="二维码定位"></a>二维码定位</h2><p>定位一张图片中的二维码需要以下几个小步骤:<br>1) 将图像转化为灰度图像<br>2) 使用 opencv 自带的 Sobel 算子进行过滤<br>Sobel 算子是一种常用的边缘检测算子,是一阶的梯度算法;<br>对噪声具有平滑作用,提供较为精确的边缘方向信息,边缘定位精度不够高;<br>当对精度要求不是很高时,是一种较为常用的边缘检测方法。<br>常见的应用和物理意义是边缘检测。<br>记得安装pyzbar模块<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"># coding:utf8</span><br><span class="line"></span><br><span class="line">import cv2</span><br><span class="line">import pyzbar.pyzbar as pyzbar</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def decodeDisplay(image):</span><br><span class="line">    barcodes = pyzbar.decode(image)</span><br><span class="line">    for barcode in barcodes:</span><br><span class="line">        # 提取条形码的边界框的位置</span><br><span class="line">        # 画出图像中条形码的边界框</span><br><span class="line">        (x, y, w, h) = barcode.rect</span><br><span class="line">        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 255), 2)</span><br><span class="line"></span><br><span class="line">        # 条形码数据为字节对象，所以如果我们想在输出图像上</span><br><span class="line">        # 画出来，就需要先将它转换成字符串</span><br><span class="line">        barcodeData = barcode.data.decode(&quot;utf-8&quot;)</span><br><span class="line">        barcodeType = barcode.type</span><br><span class="line"></span><br><span class="line">        # 绘出图像上条形码的数据和条形码类型</span><br><span class="line">        text = &quot;&#123;&#125; (&#123;&#125;)&quot;.format(barcodeData, barcodeType)</span><br><span class="line">        cv2.putText(image, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX,</span><br><span class="line">                    .5, (0, 0, 125), 2)</span><br><span class="line"></span><br><span class="line">        # 向终端打印条形码数据和条形码类型</span><br><span class="line">        print(&quot;[INFO] Found &#123;&#125; barcode: &#123;&#125;&quot;.format(barcodeType, barcodeData))</span><br><span class="line">    return image</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def detect():</span><br><span class="line">    camera = cv2.VideoCapture(0)</span><br><span class="line"></span><br><span class="line">    while True:</span><br><span class="line">        # 读取当前帧</span><br><span class="line">        ret, frame = camera.read()</span><br><span class="line">        # 转为灰度图像</span><br><span class="line">        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)</span><br><span class="line">        im = decodeDisplay(gray)</span><br><span class="line"></span><br><span class="line">        cv2.waitKey(5)</span><br><span class="line">        cv2.imshow(&quot;camera&quot;, im)</span><br><span class="line"></span><br><span class="line">    camera.release()</span><br><span class="line">    cv2.destroyAllWindows()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    detect()</span><br></pre></td></tr></table></figure></p>
<h1 id="八、目标追踪"><a href="#八、目标追踪" class="headerlink" title="八、目标追踪"></a>八、目标追踪</h1><p>camshift 利用目标的颜色直方图模型将图像转换为颜色概率分布图,初始化一个搜索窗的大小和位置,并根据上一帧得到的结果自适应调整搜索窗口的位置和大小,从而定位出当前图像中目标的中心位置。<br>tracker_base.py跟踪基类<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br></pre></td><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">import time</span><br><span class="line">class TrackerBase(object):</span><br><span class="line">    def __init__(self, window_name):</span><br><span class="line">        self.window_name = window_name</span><br><span class="line">        self.frame = None</span><br><span class="line">        self.frame_width = None</span><br><span class="line">        self.frame_height = None</span><br><span class="line">        self.frame_size = None</span><br><span class="line">        self.drag_start = None</span><br><span class="line">        self.selection = None</span><br><span class="line">        self.track_box = None</span><br><span class="line">        self.detect_box = None</span><br><span class="line">        self.display_box = None</span><br><span class="line">        self.marker_image = None</span><br><span class="line">        self.processed_image = None</span><br><span class="line">        self.display_image = None</span><br><span class="line">        self.target_center_x = None</span><br><span class="line">        self.cps = 0</span><br><span class="line">        self.cps_values = list()</span><br><span class="line">        self.cps_n_values = 20</span><br><span class="line">    #####mouse event#####</span><br><span class="line">    def onMouse(self, event, x, y, flags, params):</span><br><span class="line">        if self.frame is None:</span><br><span class="line">            return</span><br><span class="line">        if event == cv2.EVENT_LBUTTONDOWN and not self.drag_start:</span><br><span class="line">            self.track_box = None</span><br><span class="line">            self.detect_box = None</span><br><span class="line">            self.drag_start = (x, y)</span><br><span class="line">        if event == cv2.EVENT_LBUTTONUP:</span><br><span class="line">            self.drag_start = None</span><br><span class="line">            self.detect_box = self.selection</span><br><span class="line">        if self.drag_start:</span><br><span class="line">            xmin = max(0, min(x, self.drag_start[0]))</span><br><span class="line">            ymin = max(0, min(y, self.drag_start[1]))</span><br><span class="line">            xmax = min(self.frame_width, max(x, self.drag_start[0]))</span><br><span class="line">            ymax = min(self.frame_height, max(y, self.drag_start[1]))</span><br><span class="line">            self.selection = (xmin, ymin, xmax-xmin, ymax-ymin)</span><br><span class="line">    #####display selection box#####</span><br><span class="line">    def display_selection(self):</span><br><span class="line">        if self.drag_start and self.is_rect_nonzero(self.selection):</span><br><span class="line">            x, y, w, h = self.selection</span><br><span class="line">            cv2.rectangle(self.marker_image, (x, y), (x + w, y + h), (0,255, 255), 2)</span><br><span class="line">    #####calculate if rect is zero#####</span><br><span class="line">    def is_rect_nonzero(self, rect):</span><br><span class="line">        try:</span><br><span class="line">            (_,_,w,h) = rect</span><br><span class="line">            return ((w&gt;0)and(h&gt;0))</span><br><span class="line">        except:</span><br><span class="line">            try:</span><br><span class="line">                ((_,_),(w,h),a) = rect</span><br><span class="line">                return (w &gt; 0) and (h &gt; 0)</span><br><span class="line">            except:</span><br><span class="line">                return False</span><br><span class="line">    #####rgb-image callback function#####</span><br><span class="line">    def rgb_image_callback(self, data):</span><br><span class="line">        start = time.time()</span><br><span class="line">        frame = data</span><br><span class="line">        if self.frame is None:</span><br><span class="line">            self.frame = frame.copy()</span><br><span class="line">            self.marker_image = np.zeros_like(frame)</span><br><span class="line">            self.frame_size = (frame.shape[1], frame.shape[0])</span><br><span class="line">            self.frame_width, self.frame_height = self.frame_size</span><br><span class="line">            cv2.imshow(self.window_name, self.frame)</span><br><span class="line">            cv2.setMouseCallback(self.window_name,self.onMouse)</span><br><span class="line">            cv2.waitKey(3)</span><br><span class="line">        else:</span><br><span class="line">            self.frame = frame.copy()</span><br><span class="line">            self.marker_image = np.zeros_like(frame)</span><br><span class="line">            processed_image = self.process_image(frame)</span><br><span class="line">            self.processed_image = processed_image.copy()</span><br><span class="line">            self.display_selection()</span><br><span class="line">            self.display_image = cv2.bitwise_or(self.processed_image,self.marker_image)</span><br><span class="line">            ###show track-box###</span><br><span class="line">            if self.track_box is not None and self.is_rect_nonzero(self.track_box):</span><br><span class="line">                tx, ty, tw, th = self.track_box</span><br><span class="line">                cv2.rectangle(self.display_image, (tx, ty), (tx+tw,ty+th), (0, 0, 0), 2)</span><br><span class="line">            ###show detect-box###</span><br><span class="line">            elif self.detect_box is not None and self.is_rect_nonzero(self.detect_box):</span><br><span class="line">                dx, dy, dw, dh = self.detect_box</span><br><span class="line">                cv2.rectangle(self.display_image, (dx, dy), (dx+dw,dy+dh), (255, 50, 50), 2)</span><br><span class="line">                ###calcate time and fps###</span><br><span class="line">            end = time.time()</span><br><span class="line">            duration = end - start</span><br><span class="line">            fps = int(1.0/duration)</span><br><span class="line">            self.cps_values.append(fps)</span><br><span class="line">            if len(self.cps_values)&gt;self.cps_n_values:</span><br><span class="line">                self.cps_values.pop(0)</span><br><span class="line">            self.cps = int(sum(self.cps_values)/len(self.cps_values))</span><br><span class="line">            font_face = cv2.FONT_HERSHEY_SIMPLEX</span><br><span class="line">            font_scale = 0.5</span><br><span class="line">            if self.frame_size[0] &gt;= 640:</span><br><span class="line">                vstart = 25</span><br><span class="line">                voffset = int(50+self.frame_size[1]/120.)</span><br><span class="line">            elif self.frame_size[0] == 320:</span><br><span class="line">                vstart = 15</span><br><span class="line">                voffset = int(35+self.frame_size[1]/120.)</span><br><span class="line">            else:</span><br><span class="line">                vstart = 10</span><br><span class="line">                voffset = int(20 + self.frame_size[1] / 120.)</span><br><span class="line">            cv2.putText(self.display_image, &quot;CPS: &quot; + str(self.cps), (10,vstart), font_face, font_scale,(255, 255, 0))</span><br><span class="line">            cv2.putText(self.display_image, &quot;RES: &quot; +str(self.frame_size[0]) + &quot;X&quot; + str(self.frame_size[1]), (10, voffset),font_face, font_scale, (255, 255, 0))</span><br><span class="line">            ###show result###</span><br><span class="line">            cv2.imshow(self.window_name, self.display_image)</span><br><span class="line">            cv2.waitKey(3)</span><br><span class="line">    #####process image#####</span><br><span class="line">    def process_image(self, frame):</span><br><span class="line">        return frame</span><br><span class="line">if __name__==&quot;__main__&quot;:</span><br><span class="line">    cap = cv2.VideoCapture(0)</span><br><span class="line">    trackerbase = TrackerBase(&apos;base&apos;)</span><br><span class="line">    while True:</span><br><span class="line">        ret, frame = cap.read()</span><br><span class="line">        x, y = frame.shape[0:2]</span><br><span class="line">        small_frame = cv2.resize(frame, (int(y/2), int(x/2)))</span><br><span class="line">        trackerbase.rgb_image_callback(small_frame)</span><br><span class="line">        if cv2.waitKey(1) &amp; 0xFF == ord(&apos;q&apos;):</span><br><span class="line">            break</span><br><span class="line">    cap.release()</span><br><span class="line">    cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure></p>
<p>camshift.py<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">from tracker_base import TrackerBase</span><br><span class="line">class Camshift(TrackerBase):</span><br><span class="line">    def __init__(self, window_name):</span><br><span class="line">        super(Camshift, self).__init__(window_name)</span><br><span class="line">        self.detect_box = None</span><br><span class="line">        self.track_box = None</span><br><span class="line">    def process_image(self, frame):</span><br><span class="line">        try:</span><br><span class="line">            if self.detect_box is None:</span><br><span class="line">                return frame</span><br><span class="line">            src = frame.copy()</span><br><span class="line">            if self.track_box is None or not self.is_rect_nonzero(self.track_box):</span><br><span class="line">                self.track_box = self.detect_box</span><br><span class="line">                x,y,w,h = self.track_box</span><br><span class="line">                self.roi = cv2.cvtColor(frame[y:y+h, x:x+w], cv2.COLOR_BGR2HSV)</span><br><span class="line">                roi_hist = cv2.calcHist([self.roi], [0], None, [16], [0, 180])</span><br><span class="line">                self.roi_hist = cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)</span><br><span class="line">                self.term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10,1)</span><br><span class="line">            else:</span><br><span class="line">                hsv = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)</span><br><span class="line">                back_project = cv2.calcBackProject([hsv],[0],self.roi_hist,[0,180],1)</span><br><span class="line">                ret,self.track_box=cv2.CamShift(back_project,self.track_box,self.term_crit)</span><br><span class="line">                pts = cv2.boxPoints(ret)</span><br><span class="line">                pts = np.int0(pts)</span><br><span class="line">                cv2.polylines(frame,[pts],True,255,1)</span><br><span class="line">        except:</span><br><span class="line">            pass</span><br><span class="line">        return frame</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    cap = cv2.VideoCapture(0)</span><br><span class="line">    camshift = Camshift(&apos;camshift&apos;)</span><br><span class="line">    while True:</span><br><span class="line">        ret, frame = cap.read()</span><br><span class="line">        x, y = frame.shape[0:2]</span><br><span class="line">        small_frame = cv2.resize(frame, (int(y/2), int(x/2)))</span><br><span class="line">        camshift.rgb_image_callback(small_frame)</span><br><span class="line">        if cv2.waitKey(1) &amp; 0xFF == ord(&apos;q&apos;):</span><br><span class="line">            break</span><br><span class="line">    cap.release()</span><br><span class="line">    cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure></p>
<h1 id="九、光流法追踪"><a href="#九、光流法追踪" class="headerlink" title="九、光流法追踪"></a>九、光流法追踪</h1><p>光流的概念是 Gibson 在 1950 年首先提出来的。它是空间运动物体在观察成像平面上的像素运动的瞬时速度,是利用图像序列中像素在时间域上的变化以及相邻帧之间的相关性来找<br>到上一帧跟当前帧之间存在的对应关系,从而计算出相邻帧之间物体的运动信息的一种方法。一般而言,光流是由于场景中前景目标本身的移动、相机的运动,或者两者的共同运动所产生的。其计算方法可以分为三类:<br>(1)基于区域或者基于特征的匹配方法;<br>(2)基于频域的方法;<br>(3)基于梯度的方法;<br>简单来说,光流是空间运动物体在观测成像平面上的像素运动的“瞬时速度”。光流的研究是利用图像序列中的像素强度数据的时域变化和相关性来确定各自像素位置的“运动”。研究光流场的目的就是为了从图片序列中近似得到不能直接得到的运动场。</p>
<h2 id="特征点提取"><a href="#特征点提取" class="headerlink" title="特征点提取"></a>特征点提取</h2><p>good_feature.py<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">import cv2</span><br><span class="line">from tracker_base import TrackerBase</span><br><span class="line">import numpy as np</span><br><span class="line">class GoodFeatures(TrackerBase):</span><br><span class="line">    def __init__(self, window_name):</span><br><span class="line">        super(GoodFeatures, self).__init__(window_name)</span><br><span class="line">        self.feature_size = 1</span><br><span class="line">        # Good features parameters</span><br><span class="line">        self.gf_maxCorners = 200</span><br><span class="line">        self.gf_qualityLevel = 0.02</span><br><span class="line">        self.gf_minDistance = 7</span><br><span class="line">        self.gf_blockSize = 10</span><br><span class="line">        self.gf_useHarrisDetector = True</span><br><span class="line">        self.gf_k = 0.04</span><br><span class="line">        # Store all parameters together for passing to the detector</span><br><span class="line">        self.gf_params = dict(maxCorners = self.gf_maxCorners,qualityLevel = self.gf_qualityLevel,minDistance = self.gf_minDistance,blockSize = self.gf_blockSize,useHarrisDetector = self.gf_useHarrisDetector,k = self.gf_k)</span><br><span class="line">        self.keypoints = list()</span><br><span class="line">        self.detect_box = None</span><br><span class="line">        self.mask = None</span><br><span class="line">    def process_image(self, frame):</span><br><span class="line">        try:</span><br><span class="line">            if not self.detect_box:</span><br><span class="line">                return frame</span><br><span class="line">            src = frame.copy()</span><br><span class="line">            gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)</span><br><span class="line">            gray = cv2.equalizeHist(gray)</span><br><span class="line">            keypoints = self.get_keypoints(gray, self.detect_box)</span><br><span class="line">            if keypoints is not None and len(keypoints) &gt; 0:</span><br><span class="line">                for x, y in keypoints:</span><br><span class="line">                    cv2.circle(self.marker_image, (x, y), self.feature_size, (0, 255, 0), -1)</span><br><span class="line">        except:</span><br><span class="line">            pass</span><br><span class="line">        return frame</span><br><span class="line">    def get_keypoints(self, input_image, detect_box):</span><br><span class="line">        self.mask = np.zeros_like(input_image)</span><br><span class="line">        try:</span><br><span class="line">            x, y, w, h = detect_box</span><br><span class="line">        except:</span><br><span class="line">            return None</span><br><span class="line">        self.mask[y:y+h, x:x+w] = 255</span><br><span class="line">        keypoints = list()</span><br><span class="line">        kp = cv2.goodFeaturesToTrack(input_image, mask = self.mask, **self.gf_params)</span><br><span class="line">        if kp is not None and len(kp) &gt; 0:</span><br><span class="line">            for x, y in np.float32(kp).reshape(-1, 2):</span><br><span class="line">                keypoints.append((x, y))</span><br><span class="line">        return keypoints</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    cap = cv2.VideoCapture(0)</span><br><span class="line">    goodfeatures = GoodFeatures(&apos;good_feature&apos;)</span><br><span class="line">    while True:</span><br><span class="line">        ret, frame = cap.read()</span><br><span class="line">        x, y = frame.shape[0:2]</span><br><span class="line">        small_frame = cv2.resize(frame, (int(y/2), int(x/2)))</span><br><span class="line">        goodfeatures.rgb_image_callback(small_frame)</span><br><span class="line">        if cv2.waitKey(1) &amp; 0xFF == ord(&apos;q&apos;):</span><br><span class="line">            break</span><br><span class="line">    cap.release()</span><br><span class="line">    cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure></p>
<h2 id="光流跟踪"><a href="#光流跟踪" class="headerlink" title="光流跟踪"></a>光流跟踪</h2><p>lk_tracker.py<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">from good_features import GoodFeatures</span><br><span class="line">class LKTracker(GoodFeatures):</span><br><span class="line">    def __init__(self, window_name):</span><br><span class="line">        super(LKTracker, self).__init__(window_name)</span><br><span class="line">        self.feature_size = 1</span><br><span class="line">        self.lk_winSize = (10, 10)</span><br><span class="line">        self.lk_maxLevel = 2</span><br><span class="line">        self.lk_criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 20, 0.01)</span><br><span class="line">        self.lk_params = dict( winSize = self.lk_winSize,maxLevel = self.lk_maxLevel,criteria = self.lk_criteria)</span><br><span class="line">        self.detect_interval = 1</span><br><span class="line">        self.keypoints = None</span><br><span class="line">        self.detect_box = None</span><br><span class="line">        self.track_box = None</span><br><span class="line">        self.mask = None</span><br><span class="line">        self.gray = None</span><br><span class="line">        self.prev_gray = None</span><br><span class="line">    def process_image(self, frame):</span><br><span class="line">        try:</span><br><span class="line">            if self.detect_box is None:</span><br><span class="line">                return frame</span><br><span class="line">            src = frame.copy()</span><br><span class="line">            self.gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)</span><br><span class="line">            self.gray = cv2.equalizeHist(self.gray)</span><br><span class="line">            if self.track_box is None or not self.is_rect_nonzero(self.track_box):</span><br><span class="line">                self.track_box = self.detect_box</span><br><span class="line">                self.keypoints = self.get_keypoints(self.gray, self.track_box)</span><br><span class="line">            else:</span><br><span class="line">                if self.prev_gray is None:</span><br><span class="line">                    self.prev_gray = self.gray</span><br><span class="line">                self.track_box = self.track_keypoints(self.gray, self.prev_gray)</span><br><span class="line">            self.prev_gray = self.gray</span><br><span class="line">        except:</span><br><span class="line">            pass</span><br><span class="line">        return frame</span><br><span class="line">    def track_keypoints(self, gray, prev_gray):</span><br><span class="line">        img0, img1 = prev_gray, gray</span><br><span class="line">        # Reshape the current keypoints into a numpy array required by calcOpticalFlowPyrLK()</span><br><span class="line">        p0 = np.float32([p for p in self.keypoints]).reshape(-1, 1, 2)</span><br><span class="line">        # Calculate the optical flow from the previous frame to the current frame</span><br><span class="line">        p1, st, err = cv2.calcOpticalFlowPyrLK(img0, img1, p0, None, **self.lk_params)</span><br><span class="line">        try:</span><br><span class="line">            # Do the reverse calculation: from the current frame to the previous frame</span><br><span class="line">            p0r, st, err = cv2.calcOpticalFlowPyrLK(img1, img0, p1, None, **self.lk_params)</span><br><span class="line">            # Compute the distance between corresponding points in the two flows</span><br><span class="line">            d = abs(p0-p0r).reshape(-1, 2).max(-1)</span><br><span class="line">            # If the distance between pairs of points is &lt; 1 pixel, set a value in the &quot;good&quot; array to True, otherwise False</span><br><span class="line">            good = d&lt;1</span><br><span class="line">            new_keypoints = list()</span><br><span class="line">            for(x, y), good_flag in zip(p1.reshape(-1, 2), good):</span><br><span class="line">                if not good_flag:</span><br><span class="line">                    continue</span><br><span class="line">                new_keypoints.append((x, y))</span><br><span class="line">                cv2.circle(self.marker_image, (x, y), self.feature_size, (255, 255, 0), -1)</span><br><span class="line">            self.keypoints = new_keypoints</span><br><span class="line">            # Convert the keypoints list to a numpy array</span><br><span class="line">            keypoints_array = np.float32([p for p in self.keypoints]).reshape(-1, 1, 2)</span><br><span class="line">            if len(self.keypoints)&gt;6:</span><br><span class="line">                track_box = cv2.boundingRect(keypoints_array)</span><br><span class="line">            else:</span><br><span class="line">                track_box = cv2.boundingRect(keypoints_array)</span><br><span class="line">        except:</span><br><span class="line">            track_box = None</span><br><span class="line">        return track_box</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    cap = cv2.VideoCapture(0)</span><br><span class="line">    lk_tracker = LKTracker(&apos;lk_tracker&apos;)</span><br><span class="line">    while True:</span><br><span class="line">        ret, frame = cap.read()</span><br><span class="line">        x, y = frame.shape[0:2]</span><br><span class="line">        small_frame = cv2.resize(frame, (int(y/2), int(x/2)))</span><br><span class="line">        lk_tracker.rgb_image_callback(small_frame)</span><br><span class="line">        if cv2.waitKey(1) &amp; 0xFF == ord(&apos;q&apos;):</span><br><span class="line">            break</span><br><span class="line">    cap.release()</span><br><span class="line">    cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure></p>
<h1 id="九、KCF-Kalman-目标跟踪"><a href="#九、KCF-Kalman-目标跟踪" class="headerlink" title="九、KCF+Kalman 目标跟踪"></a>九、KCF+Kalman 目标跟踪</h1><p>KCF 是一种鉴别式追踪方法,这类方法一般都是在追踪过程中训练一个目标检测器,使用目标检测器去检测下一帧预测位置是否是目标,然后再使用新检测结果去更新训练集进而更新目标检测器。而在训练目标检测器时一般选取目标区域为正样本,目标的周围区域为负样本,当然越靠近目标的区域为正样本的可能性越大。<br>Kcf 的主要贡献:<br>使用目标周围区域的循环矩阵采集正负样本,利用脊回归训练目标检测器,并成功的利用循环矩阵在傅里叶空间可对角化的性质将矩阵的运算转化为向量的 Hadamad 积,即元素的点乘,大大降低了运算量,提高了运算速度,使算法满足实时性要求。将线性空间的脊回归通过核函数映射到非线性空间,在非线性空间通过求解一个对偶问题和某些常见的约束,同样的可以使用循环矩阵傅里叶空间对角化简化计算。给出了一种将多通道数据融入该算法的途径<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">from tracker_base import TrackerBase</span><br><span class="line">class KcfKalmanTracker(TrackerBase):</span><br><span class="line">    def __init__(self, window_name):</span><br><span class="line">        super(KcfKalmanTracker, self).__init__(window_name)</span><br><span class="line">        self.tracker = cv2.TrackerKCF_create()</span><br><span class="line">        self.detect_box = None</span><br><span class="line">        self.track_box = None</span><br><span class="line">        ####init kalman####</span><br><span class="line">        self.kalman = cv2.KalmanFilter(4, 2)</span><br><span class="line">        self.kalman.measurementMatrix = np.array([[1,0,0,0],[0,1,0,0]],np.float32)</span><br><span class="line">        self.kalman.transitionMatrix=np.array([[1,0,1,0],[0,1,0,1],[0,0,1,0],[0,0,0,1]],np.float32)</span><br><span class="line">        self.kalman.processNoiseCov=np.array([[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]],np.float32)*0.03</span><br><span class="line">        self.measurement = np.array((2,1),np.float32)</span><br><span class="line">        self.prediction = np.array((2,1),np.float32)</span><br><span class="line">    def process_image(self, frame):</span><br><span class="line">        try:</span><br><span class="line">            if self.detect_box is None:</span><br><span class="line">                return frame</span><br><span class="line">            src = frame.copy()</span><br><span class="line">            if self.track_box is None or not self.is_rect_nonzero(self.track_box):</span><br><span class="line">                self.track_box = self.detect_box</span><br><span class="line">                if self.tracker is None:</span><br><span class="line">                    raise Exception(&quot;tracker not init&quot;)</span><br><span class="line">                status = self.tracker.init(src, self.track_box)</span><br><span class="line">                if not status:</span><br><span class="line">                    raise Exception(&quot;tracker initial failed&quot;)</span><br><span class="line">            else:</span><br><span class="line">                self.track_box = self.track(frame)</span><br><span class="line">        except:</span><br><span class="line">            pass</span><br><span class="line">        return frame</span><br><span class="line">    def track(self, frame):</span><br><span class="line">        status, coord = self.tracker.update(frame)</span><br><span class="line">        center=np.array([[np.float32(coord[0]+coord[2]/2)],[np.float32(coord[1]+coord[3]/2)]])</span><br><span class="line">        self.kalman.correct(center)</span><br><span class="line">        self.prediction = self.kalman.predict()</span><br><span class="line">        cv2.circle(frame, (int(self.prediction[0]),int(self.prediction[1])),4,(255,60,100),2)</span><br><span class="line">        round_coord = (int(coord[0]), int(coord[1]), int(coord[2]), int(coord[3]))</span><br><span class="line">        return round_coord</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    cap = cv2.VideoCapture(0)</span><br><span class="line">    kcfkalmantracker = KcfKalmanTracker(&apos;base&apos;)</span><br><span class="line">    while True:</span><br><span class="line">        ret, frame = cap.read()</span><br><span class="line">        x, y = frame.shape[0:2]</span><br><span class="line">        small_frame = cv2.resize(frame, (int(y/2), int(x/2)))</span><br><span class="line">        kcfkalmantracker.rgb_image_callback(small_frame)</span><br><span class="line">        if cv2.waitKey(1) &amp; 0xFF == ord(&apos;q&apos;):</span><br><span class="line">            break</span><br><span class="line">    cap.release()</span><br><span class="line">    cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure></p>
<hr>
<p>文章参考德强师兄博客<a href="https://purethought.cn/" target="_blank" rel="noopener">https://purethought.cn/</a></p>

            </div>

            <!-- Post Comments -->
            
    <!-- 使用 DISQUS_CLICK -->
<div id="disqus-comment">
    <div id="disqus_thread"></div>

<!-- add animation -->
<style>
	.disqus_click_btn {
            line-height: 30px;
            margin: 0;
            min-width: 50px;
            padding: 0 14px;
            display: inline-block;
            font-family: "Roboto", "Helvetica", "Arial", sans-serif;
            font-size: 14px;
            font-weight: 400;
            text-transform: uppercase;
            letter-spacing: 0;
            overflow: hidden;
            will-change: box-shadow;
            transition: box-shadow .2s cubic-bezier(.4, 0, 1, 1), background-color .2s cubic-bezier(.4, 0, .2, 1), color .2s cubic-bezier(.4, 0, .2, 1);
            outline: 0;
            cursor: pointer;
            text-decoration: none;
            text-align: center;
            vertical-align: middle;
            border: 0;
            background: rgba(158, 158, 158, .2);
            box-shadow: 0 2px 2px 0 rgba(0, 0, 0, .14), 0 3px 1px -2px rgba(0, 0, 0, .2), 0 1px 5px 0 rgba(0, 0, 0, .12);
            color: #fff;
            background-color: #7EC0EE;
            text-shadow: 0
        }
</style>
	
<div class="btn_click_load" id="disqus_bt"> 
    <button class="disqus_click_btn">点击查看评论</button>
</div>

<!--
<script type="text/javascript">
$('.btn_click_load').click(function() {
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'http-lzqmove-tech'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    document.getElementById('disqus_bt').style.display = "none";
});
</script>
-->
<script type="text/javascript">
    var disqus_config = function () {
        this.page.url = 'http://yoursite.com/2019/08/26/python-opencv/';  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = 'http://yoursite.com/2019/08/26/python-opencv/'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
</script>

<script type="text/javascript">
    $('.btn_click_load').click(function() {  //click to load comments
        (function() { // DON'T EDIT BELOW THIS LINE
            var d = document;
            var s = d.createElement('script');
            s.src = '//http-lzqmove-tech.disqus.com/embed.js';
            s.setAttribute('data-timestamp', + new Date());
            (d.head || d.body).appendChild(s);
        })();
        $('.btn_click_load').css('display','none');
    });
</script>
</div>
<style>
    #disqus-comment{
        background-color: #eee;
        padding: 2pc;
    }
</style>


        </div>
        <!-- Copyright 版权 start -->
                <div id="copyright">
            <ul>
                <li>&copy;Powered By <a href="https://hexo.io/zh-cn/" style="border-bottom: none;">hexo</a></li>
                <li>Design: <a href="https://github.com/lzqmove " style="border-bottom: none;">LZQ</a></li>
            </ul>
            
                <span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span>
			
        </div>
    </div>
</body>



 	
</html>
